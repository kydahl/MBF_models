#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section*
Estimating from complete data
\end_layout

\begin_layout Standard
!!! NB: The definition of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

 used here might be the 
\bar under
transposes
\bar default
 of what I have been using in the other work.
 Double-check that everying is correct
\end_layout

\begin_layout Standard
Suppose we have observed data 
\begin_inset Formula $x_{1},\ldots x_{N}$
\end_inset

 where each 
\begin_inset Formula $x_{i}$
\end_inset

 is a realization of a Markov jump process 
\begin_inset Formula $\left\{ X_{t}\right\} _{0\le t\le\tau_{i}}$
\end_inset

 up to to the time of absorption.
 
\end_layout

\begin_layout Standard
We can condense each observation 
\begin_inset Formula $x$
\end_inset

 into 
\begin_inset Formula $\left\{ \left(i_{k},u_{k}\right)\right\} _{k=0,1,\ldots n}$
\end_inset

 where the 
\begin_inset Formula $i_{0},\ldots,i_{n}$
\end_inset

 are the states visited prior to absorption and the 
\begin_inset Formula $u_{0},\ldots,u_{n}$
\end_inset

 are the corresponding times spent in these states.
 
\end_layout

\begin_layout Standard
Assume that the underlying distribution is a phase type distribution with
 representation 
\begin_inset Formula $\textrm{PH}_{p}\left(\alpha,A\right)$
\end_inset

.
 Let 
\begin_inset Formula $\theta=\left(\alpha,A\right)$
\end_inset

 be the parameter to be estimated and let 
\begin_inset Formula $L_{c}\left(\theta;x\right)$
\end_inset

 denote the complete likelihood function for the observation 
\begin_inset Formula $x=\left\{ \left(i_{k},u_{k}\right)\right\} _{k=0,1,\ldots n}$
\end_inset

.
 Then the 
\begin_inset Formula $u_{k}$
\end_inset

 are realizations of exponentially distributed random variables with parameters
 
\begin_inset Formula $\lambda_{i_{k}}=-t_{i_{k}i_{k}}$
\end_inset

 and 
\begin_inset Formula $i_{0},\ldots,i_{n}$
\end_inset

 is a realization of a Markov chain that has transition probabilities
\begin_inset Formula 
\[
p_{ij}=-\frac{t_{ij}}{t_{ii}},p_{i,p+1}=-\frac{t_{i}}{t_{ii}}
\]

\end_inset

A sample path argument then shows that the likelihood function evaluated
 at 
\begin_inset Formula $x$
\end_inset

 is given by 
\begin_inset Formula 
\[
L_{c}\left(\theta;x\right)=\pi_{i_{0}}\lambda_{i_{0}}e^{-\lambda_{i_{0}}u_{0}}p_{i_{0}i_{1}}\lambda_{i_{1}}e^{-\lambda_{i_{1}}u_{1}}\cdots p_{i_{n-1}i_{n}}\lambda_{i_{n}}e^{-\lambda_{i_{n}}u_{n}}p_{i_{n},p+1}
\]

\end_inset

Now 
\begin_inset Formula $\lambda_{i}p_{ij}=t_{ij}$
\end_inset

 and 
\begin_inset Formula $\lambda_{i}=-t_{ii}=\sum_{j\neq i}t_{ij}+t_{i}$
\end_inset

 from which we may rewrite the likelihood as
\begin_inset Formula 
\begin{align*}
L_{c}\left(\theta;x\right) & =\pi_{i_{0}}\left(\prod_{i=1}^{p}\prod_{j=1,j\neq i}^{p}t_{ij}^{N_{ij}}e^{-t_{ij}Z_{i}}\right)\prod_{j=1}^{p}t_{i}^{N_{i}}e^{-t_{i}Z_{i}}
\end{align*}

\end_inset

where 
\begin_inset Formula $N_{ij}$
\end_inset

 is the number of jumps from state 
\begin_inset Formula $i$
\end_inset

 to state 
\begin_inset Formula $j$
\end_inset

 in the realization 
\begin_inset Formula $x$
\end_inset

, 
\begin_inset Formula $Z_{i}$
\end_inset

 is the total time spent in state 
\begin_inset Formula $i$
\end_inset

, and 
\begin_inset Formula $N_{i}$
\end_inset

 is the number of jumps from state 
\begin_inset Formula $i$
\end_inset

 to state 
\begin_inset Formula $p+1$
\end_inset

, which in this case is zero for all but one state, from which the process
 exits to the absorbing state.
 
\end_layout

\begin_layout Standard
Now suppose that we have 
\begin_inset Formula $N$
\end_inset

 i.i.d.
 trajectories 
\begin_inset Formula $x_{1},\ldots,x_{n}$
\end_inset

 sampled from 
\begin_inset Formula $\textrm{PH}_{p}\left(\alpha,A\right)$
\end_inset

.
 Then the likelihood function is just the product of the single-point likelihood
s:
\begin_inset Formula 
\begin{align*}
L_{c}\left(\theta;x_{1},\ldots,x_{n}\right) & =\left(\prod_{i=1}^{p}\pi_{i}^{B_{i}}\right)\left(\prod_{i=1}^{p}\prod_{j=1,j\neq i}^{p}t_{ij}^{N_{ij}}e^{-t_{ij}Z_{i}}\right)\left(\prod_{j=1}^{p}t_{i}^{N_{i}}e^{-t_{i}Z_{i}}\right)
\end{align*}

\end_inset

where 
\begin_inset Formula $B_{i}$
\end_inset

 is the number of observed processes that initiate in state 
\begin_inset Formula $i$
\end_inset

, 
\begin_inset Formula $N_{ij}$
\end_inset

 is the number of observed jumps from state 
\begin_inset Formula $i$
\end_inset

 to state 
\begin_inset Formula $j$
\end_inset

 in ALL the processes, 
\begin_inset Formula $Z_{i}$
\end_inset

 is the total time spent in state 
\begin_inset Formula $i$
\end_inset

 in ALL processes, and 
\begin_inset Formula $N_{i}$
\end_inset

 is the number of processes that exit the absorbing state from state 
\begin_inset Formula $i$
\end_inset

.
 The 
\begin_inset Formula $B_{i}$
\end_inset

, 
\begin_inset Formula $N_{ij}$
\end_inset

, 
\begin_inset Formula $N_{i}$
\end_inset

, and 
\begin_inset Formula $Z_{i}$
\end_inset

 are sufficient statistics.
 
\end_layout

\begin_layout Standard
Note that in this form 
\begin_inset Formula $t_{ii}$
\end_inset

 is no longer a parameter and has been replaced by 
\begin_inset Formula $t_{i}$
\end_inset

.
 This is because 
\begin_inset Formula $-t_{ii}=t_{i}+\sum_{j\neq i}t_{ij}$
\end_inset

 .
\end_layout

\begin_layout Standard
We now optimize the likelihood function by considering the log-likelihood
 function
\begin_inset Formula 
\[
\ell_{c}\left(\theta;x_{1},\ldots x_{N}\right)=\sum_{i=1}^{p}B_{i}\log\left(\pi_{i}\right)+\sum_{i=1}^{p}\sum_{i=1,j\neq i}^{p}N_{ij}\log\left(t_{ij}\right)-\sum_{i=1}^{p}\sum_{i=1,j\neq i}^{p}Z_{i}t_{ij}+\sum_{i=1}^{p}N_{i}\log\left(t_{i}\right)-\sum_{i=1}^{p}Z_{i}t_{i}
\]

\end_inset

Differentiating 
\begin_inset Formula $\ell_{c}$
\end_inset

 wrt 
\begin_inset Formula $t_{ij}$
\end_inset

 and setting equal to zero results in 
\begin_inset Formula $t_{ij}=\frac{N_{ij}}{Z_{i}}$
\end_inset

.
 Similarly differentiating wrt 
\begin_inset Formula $t_{i}$
\end_inset

 implies that 
\begin_inset Formula $t_{i}=\frac{N_{i}}{Z_{i}}$
\end_inset

.
\end_layout

\begin_layout Standard
Now maximizing the 
\begin_inset Formula $\pi_{i}$
\end_inset

 is constrained to 
\begin_inset Formula $\sum\pi_{i}=1$
\end_inset

.
 Introduce the Lagrange multiplier 
\begin_inset Formula $c$
\end_inset

 and consider the function 
\begin_inset Formula 
\[
H\left(\pi_{1},\ldots,\pi_{p}\right)=\sum_{i=1}^{p}B_{i}\log\left(\pi_{i}\right)-c\left(\pi_{1}+\cdots+\pi_{p}-1\right)
\]

\end_inset

Hence 
\begin_inset Formula 
\[
\nabla H=\begin{bmatrix}\frac{B_{1}}{\pi_{1}}-c\\
\frac{B_{2}}{\pi_{2}}-c\\
\vdots\\
\frac{B_{p}}{\pi_{p}}-c
\end{bmatrix}=0
\]

\end_inset

which implies that 
\begin_inset Formula $B_{i}=c\pi_{i}$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset

.
 Summing over 
\begin_inset Formula $i$
\end_inset

 then yields 
\begin_inset Formula $c=\sum_{i=1}^{p}B_{i}=N$
\end_inset

 and thus 
\begin_inset Formula $\pi_{i}=\frac{B_{i}}{N}$
\end_inset

.
 By considering the second-order derivatives of 
\begin_inset Formula $\ell_{c}$
\end_inset

 we see that the Hessian matrix is negative definite and therefore the points
 described above do in fact maximize the likelihood function.
 Hence we obtain the maximum likelihood estimators:
\begin_inset Formula 
\[
\hat{t}_{ij}=\frac{N_{ij}}{Z_{i}},\hat{t}_{i}=\frac{N_{i}}{Z_{i}},\hat{\pi}_{i}=\frac{B_{i}}{N}
\]

\end_inset

and the maximum likelihood estimator for 
\begin_inset Formula $t_{ii}$
\end_inset

 is 
\begin_inset Formula $\hat{t}_{ii}=\hat{t}_{i}-\sum_{j\neq i}\hat{t}_{ij}$
\end_inset

.
\end_layout

\begin_layout Section*
The EM algorithm
\end_layout

\begin_layout Standard
Let 
\begin_inset Formula $X$
\end_inset

 denote the complete data and 
\begin_inset Formula $Y=y$
\end_inset

 the incomplete observed data.
 Then there is a many-to-one map 
\begin_inset Formula $\phi$
\end_inset

 such that 
\begin_inset Formula $\phi\left(X\right)=Y$
\end_inset

.
 Let 
\begin_inset Formula $L_{c}$
\end_inset

 and 
\begin_inset Formula $\ell_{c}$
\end_inset

 denote the complete data likelihood and log-likelihood respectively while
 we reserve 
\begin_inset Formula $L$
\end_inset

 and 
\begin_inset Formula $\ell$
\end_inset

 for the incomplete likelihoods.
 The EM algorithm works as follows
\end_layout

\begin_layout Enumerate
Initialize with an 
\begin_inset Quotes eld
\end_inset

arbitrary
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $\theta_{0}$
\end_inset

 and let 
\begin_inset Formula $n=0$
\end_inset


\end_layout

\begin_layout Enumerate
(E-step) Calculate the function 
\begin_inset Formula 
\[
h:\theta\to\mathbb{E}_{\theta_{n}}\left(\ell_{c}\left(\theta;X\right)|Y=y\right)
\]

\end_inset


\end_layout

\begin_layout Enumerate
(M-step) Let 
\begin_inset Formula $\theta_{n+1}:=\mathrm{argmax}_{\theta}h\left(\theta\right)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $n=n+1$
\end_inset

; GOTO 2
\end_layout

\begin_layout Standard
Then 
\begin_inset Formula $L\left(\theta_{n+1};y\right)\ge L\left(\theta_{n};y\right)$
\end_inset

 for all 
\begin_inset Formula $n$
\end_inset

 and as 
\begin_inset Formula $n\to\infty$
\end_inset

, 
\begin_inset Formula $L\left(\theta_{n};y\right)$
\end_inset

 converges to either a local (or global) maximum or saddle point for 
\begin_inset Formula $L$
\end_inset

.
\end_layout

\begin_layout Section*
Estimating continuous phase-type distributions via the EM algorithm
\end_layout

\begin_layout Standard
Consider 
\begin_inset Formula $y_{1},\ldots,y_{N}$
\end_inset

 observed data which are assumed to be realizations from 
\begin_inset Formula $Y_{1},\ldots,Y_{N}$
\end_inset

 i.i.d.
 
\begin_inset Formula $\textrm{PH}_{p}\left(\alpha,A\right)$
\end_inset

.
 Hence 
\begin_inset Formula $Y_{i}$
\end_inset

 is the time until absorption of an unobserved Markov jump process 
\begin_inset Formula $\left\{ X_{t}^{i}\right\} _{t\ge0}$
\end_inset

.
 We now establish an EM algorithm for maximizing the likelihood function
\begin_inset Formula 
\[
L\left(\alpha,A;y\right)=\prod_{i=1}^{N}\alpha^{T}e^{Ay_{i}}\boldsymbol{t}
\]

\end_inset

where 
\begin_inset Formula $\boldsymbol{t}=-A\boldsymbol{1}$
\end_inset

.
 If we had complete data, we can calculate the MLE for each parameter directly
 as described above but otherwise we have to rely on the EM algorithm.
 The method will be to calculate the conditional expectations for the sufficient
 statistics 
\begin_inset Formula $B_{i}$
\end_inset

, 
\begin_inset Formula $Z_{i}$
\end_inset

, 
\begin_inset Formula $N_{ij}$
\end_inset

, and 
\begin_inset Formula $N_{i}$
\end_inset

 under the estimated parameters 
\begin_inset Formula $\left(\alpha_{n},A_{n}\right)$
\end_inset

 for the given data.
 
\end_layout

\begin_layout Standard
Suppose we have a single observation 
\begin_inset Formula $y$
\end_inset

.
 It follows from 
\begin_inset Formula $B_{i}=1\left\{ X_{0}=i\right\} $
\end_inset

 and 
\begin_inset Formula $\mathbb{E}\left(B_{i}|Y=y\right)=\mathbb{E}_{\left(\alpha,A\right)}\left(B_{i}|Y=y\right)$
\end_inset

 is given by
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left(B_{i}|Y=y\right) & =\mathbb{E}\left(1\left\{ X_{0}=i\right\} |Y=y\right)\\
 & =\mathbb{E}\left(X_{0}=i|Y=y\right)\\
 & =\frac{\mathbb{P}\left(X_{0}=i,Y\in dy\right)}{\mathbb{P}\left(Y\in dy\right)}\\
 & =\frac{\mathbb{P}\left(X_{0}=i\right)\mathbb{P}\left(Y\in dy|X_{0}=i\right)}{\mathbb{P}\left(Y\in dy\right)}\\
 & =\frac{\alpha_{i}e_{i}^{T}e^{Ay}\boldsymbol{t}}{\alpha^{T}e^{Ay}\boldsymbol{t}}
\end{align*}

\end_inset

where 
\begin_inset Formula $e_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th unit vector.
 Concerning 
\begin_inset Formula $Z_{i}$
\end_inset

, we get that 
\begin_inset Formula 
\begin{align*}
\mathbb{\mathbb{E}}\left(Z_{i}|Y=y\right) & =\mathbb{E}\left(\int_{0}^{y}1\left\{ X_{u}=i\right\} du|Y=y\right)\\
 & =\int_{0}^{y}\mathbb{P}\left(\left\{ X_{u}=i\right\} |Y=y\right)du\\
 & =\int_{0}^{y}\frac{\mathbb{P}\left(Y\in dy|X_{u}=i\right)\mathbb{P}\left(X_{u}=i\right)}{\mathbb{P}\left(Y\in dy|\right)}du\\
 & =\int_{0}^{y}\frac{e_{i}^{T}e^{A\left(y-u\right)}\boldsymbol{t}\alpha e^{Au}e_{i}}{\alpha e^{Ay}\boldsymbol{t}}du
\end{align*}

\end_inset

I'll skip over the details but this is what we get for 
\begin_inset Formula $N_{ij}$
\end_inset


\begin_inset Formula 
\[
\mathbb{E}\left(N_{ij}|Y=y\right)=t_{ij}e_{j}^{T}\int_{0}^{y}e^{A\left(y-s\right)}\boldsymbol{t}\alpha e^{As}dse_{i}/\alpha e^{Ay}\boldsymbol{t}
\]

\end_inset

and finally
\begin_inset Formula 
\[
\mathbb{E}\left(N_{i}|Y=y\right)=\frac{\alpha e^{A}e_{i}\boldsymbol{t}_{i}}{\alpha e^{Ay}\boldsymbol{t}}
\]

\end_inset

Define the matrix 
\begin_inset Formula $\boldsymbol{J}\left(y;\alpha,A\right)=\int_{0}^{y}e^{A\left(y-u\right)}\boldsymbol{t}\alpha e^{Au}du$
\end_inset

 then we can write
\begin_inset Formula 
\begin{align*}
\mathbb{\mathbb{E}}\left(Z_{i}|Y=y\right) & =\frac{\boldsymbol{J}\left(y;\alpha,A\right)_{ii}}{\alpha e^{Ay}\boldsymbol{t}}\\
\mathbb{\mathbb{E}}\left(N_{ij}|Y=y\right) & =t_{ij}\frac{\boldsymbol{J}\left(y;\alpha,A\right)_{ji}}{\alpha e^{Ay}\boldsymbol{t}}
\end{align*}

\end_inset

Both 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 and 
\begin_inset Formula $e^{Ay}$
\end_inset

 can calculated by evaluating the matrix-exponential (see Theorem A.2.1 for
 why the following is true):
\begin_inset Formula 
\[
\exp\left(\begin{bmatrix}A & \boldsymbol{t}\alpha^{T}\\
0 & A
\end{bmatrix}y\right)=\begin{bmatrix}e^{Ay} & \boldsymbol{J}\\
0 & e^{Ay}
\end{bmatrix}
\]

\end_inset

For more than one data point, say 
\begin_inset Formula $y_{1},\ldots,y_{N}$
\end_inset

, we simply sum the above formulas of each sufficient statistic over the
 data points.
 Here's the EM algorithm for this case
\end_layout

\begin_layout Enumerate
Initialize with an 
\begin_inset Quotes eld
\end_inset

arbitrary
\begin_inset Quotes erd
\end_inset

 
\begin_inset Formula $\left(\alpha,A\right)$
\end_inset

 where 
\begin_inset Formula $A=\left\{ t_{ij}\right\} $
\end_inset

.
\end_layout

\begin_layout Enumerate
(E step) Calculate
\begin_inset Formula 
\begin{align*}
\mathbb{E}\left(B_{i}|Y=y\right) & =\sum_{k=1}^{N}\frac{\alpha_{i}\boldsymbol{e}_{i}^{T}e^{Ay_{k}}\boldsymbol{t}}{\alpha^{T}e^{Ay_{k}}\boldsymbol{t}}\\
\mathbb{E}\left(Z_{i}|Y=y\right) & =\sum_{k=1}^{N}\frac{\boldsymbol{J}\left(y_{k};\alpha,A\right)_{ii}}{\alpha^{T}e^{Ay_{k}}\boldsymbol{t}}\\
\mathbb{E}\left(N_{ij}|Y=y\right) & =\sum_{k=1}^{N}t_{ij}\frac{\boldsymbol{J}\left(y_{k};\alpha,A\right)_{ji}}{\alpha^{T}e^{Ay_{k}}\boldsymbol{t}}\\
\mathbb{E}\left(N_{i}|Y=y\right) & =\sum_{k=1}^{N}\frac{\alpha^{T}e^{Ay_{k}}\boldsymbol{e}_{i}t_{i}}{\alpha^{T}e^{Ay_{k}}\boldsymbol{t}}
\end{align*}

\end_inset

where 
\begin_inset Formula $e_{i}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

-th unit COLUMN vector and 
\begin_inset Formula $\boldsymbol{t}=-A\boldsymbol{1}=\left\{ t_{1},\ldots,t_{p}\right\} $
\end_inset


\end_layout

\begin_layout Enumerate
(M step) Let
\begin_inset Formula 
\begin{align*}
\hat{\alpha}_{i} & =\frac{1}{N}\mathbb{E}\left(B_{i}|Y=y\right)\\
\hat{t}_{ij} & =\frac{\mathbb{E}\left(N_{ij}|Y=y\right)}{\mathbb{E}\left(Z_{i}|Y=y\right)}=\begin{bmatrix}\frac{n_{11}}{z_{1}} & \frac{n_{12}}{z_{1}} & \cdots & \frac{n_{1p}}{z_{1}}\\
\frac{n_{21}}{z_{2}} & \frac{n_{22}}{z_{2}} & \cdots & \frac{n_{2p}}{z_{2}}\\
\vdots & \vdots & \ddots & \vdots\\
\frac{n_{p1}}{z_{p}} & \frac{n_{p2}}{z_{p}} & \cdots & \frac{n_{pp}}{z_{p}}
\end{bmatrix}\\
\hat{t}_{i} & =\frac{\mathbb{E}\left(N_{i}|Y=y\right)}{\mathbb{E}\left(Z_{i}|Y=y\right)}\\
\hat{t}_{ii} & =-\sum_{j\neq i}\hat{t}_{ij}-\hat{t}_{i}
\end{align*}

\end_inset


\end_layout

\begin_layout Enumerate
Assign 
\begin_inset Formula $\alpha=\hat{\alpha}$
\end_inset

 and 
\begin_inset Formula $A=\hat{A}=\left\{ \hat{t}_{ij}\right\} _{i,j=1,\ldots,p}$
\end_inset

 and 
\begin_inset Formula $\hat{t}=\left(\hat{t}_{1},\ldots,\hat{t}_{p}\right)^{T}$
\end_inset

 and GOTO 2 
\end_layout

\begin_layout Standard
Note that if an intensity (?) is preset to zero, then it will remain zero
 throughout all the iterations.
 This allows for estimating submodels in an easy way by prespecifying a
 certain structure such as a generalized Erlang distribution.
 (I think this means that if we initialize with certain 
\begin_inset Formula $t_{ij}$
\end_inset

's set to zero, they'll remain zero as the process proceeds.
 This is pretty handy because my 
\begin_inset Quotes eld
\end_inset

special case
\begin_inset Quotes erd
\end_inset

 models all have this assumption).
\end_layout

\begin_layout Section*
Exponentials of certain structured matrices
\end_layout

\begin_layout Standard
We must calculate 
\begin_inset Formula $e^{Ay}$
\end_inset

 for certain structured matrices 
\begin_inset Formula $A$
\end_inset

 and scalars 
\begin_inset Formula $y$
\end_inset

 as well as
\begin_inset Formula 
\[
\exp\left(\begin{bmatrix}A & \boldsymbol{t}\alpha\\
0 & A
\end{bmatrix}y\right)=\begin{bmatrix}e^{Ay} & \boldsymbol{J}\\
0 & e^{Ay}
\end{bmatrix}
\]

\end_inset


\end_layout

\begin_layout Standard
We will often encounter lower triangular matrices
\begin_inset Formula 
\[
A=\begin{bmatrix}d_{1} & l_{12} & l_{13} & \cdots & l_{1n}\\
0 & d_{2} & l_{23} & \cdots & l_{2n}\\
\vdots & \ddots & \ddots & \ddots & \vdots\\
\vdots & \ddots & \ddots & d_{n-1} & l_{n-1,n}\\
0 & \cdots & \cdots & 0 & d_{n}
\end{bmatrix}
\]

\end_inset

Let 
\begin_inset Formula $\mathrm{diag}\left(A\right)$
\end_inset

 be the diagonal elements of 
\begin_inset Formula $A$
\end_inset

, 
\begin_inset Formula $D=D_{\mathrm{diag}\left(A\right)}$
\end_inset

 be the diagonal matrix with the same diagonal entries as 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $L=A-D$
\end_inset

 be the lower-triangular part of 
\begin_inset Formula $A$
\end_inset

.
 Then 
\begin_inset Formula $LD=DL$
\end_inset

 and hence
\begin_inset Formula 
\[
e^{A}=e^{L+D}=e^{D}e^{L}
\]

\end_inset

Since 
\begin_inset Formula $L$
\end_inset

 is nilpotent (let 
\begin_inset Formula $L^{m}=0$
\end_inset

 with 
\begin_inset Formula $m\le n$
\end_inset

) then
\begin_inset Formula 
\begin{align*}
e^{L} & =I+L+\frac{1}{2}L^{2}+\cdots+\frac{1}{\left(m-1\right)!}L^{m-1}\\
e^{L} & =\sum_{i=0}^{m-1}\frac{1}{i!}L^{i}
\end{align*}

\end_inset

Now let 
\begin_inset Formula $M=\begin{bmatrix}A & \boldsymbol{t}\alpha\\
0 & A
\end{bmatrix}y=\begin{bmatrix}Ay & \boldsymbol{t}\alpha y\\
0 & Ay
\end{bmatrix}$
\end_inset

.
 This is also an upper triangular matrix.
 Let 
\begin_inset Formula $D_{M}=D_{\textrm{diag}\left(M\right)}$
\end_inset

 and 
\begin_inset Formula $L_{M}=M-D_{M}$
\end_inset

.
 Then
\begin_inset Formula 
\[
e^{M}=e^{D_{M}}e^{L_{M}}
\]

\end_inset

Now 
\begin_inset Formula $D_{M}=D_{\mathrm{diag}\left(Ay\right)}\oplus D_{\mathrm{diag}\left(Ay\right)}$
\end_inset

 so that 
\begin_inset Formula $e^{D_{M}}=\begin{bmatrix}e^{Dy} & 0\\
0 & e^{Dy}
\end{bmatrix}$
\end_inset


\begin_inset Formula 
\begin{align*}
\begin{bmatrix}e^{Ay} & \boldsymbol{J}\\
0 & e^{Ay}
\end{bmatrix} & =\exp\left(\begin{bmatrix}A & \boldsymbol{t}\alpha\\
0 & A
\end{bmatrix}y\right)\\
\boldsymbol{J} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\exp M\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}e^{D_{M}}e^{L_{M}}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}e^{Dy} & 0\\
0 & e^{Dy}
\end{bmatrix}e^{L_{M}}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}e^{Dy} & 0\\
0 & e^{Dy}
\end{bmatrix}\exp\begin{bmatrix}\left(A-D\right)y & \boldsymbol{t}\alpha y\\
0 & \left(A-D\right)y
\end{bmatrix}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\begin{bmatrix}e^{Dy} & \boldsymbol{0}_{n}\end{bmatrix}\exp\begin{bmatrix}\left(A-D\right)y & \boldsymbol{t}\alpha y\\
0 & \left(A-D\right)y
\end{bmatrix}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}\begin{bmatrix}e^{Dy} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right)y & \boldsymbol{t}\alpha y\\
0 & \left(A-D\right)y
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix} & =\begin{bmatrix}\left(A-D\right)^{2} & \left(A-D\right)\boldsymbol{t}\alpha+\boldsymbol{t}\alpha\left(A-D\right)\\
0 & \left(A-D\right)^{2}
\end{bmatrix}\\
\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}\begin{bmatrix}\left(A-D\right)^{2} & \left(A-D\right)\boldsymbol{t}\alpha+\boldsymbol{t}\alpha\left(A-D\right)\\
0 & \left(A-D\right)^{2}
\end{bmatrix} & =\begin{bmatrix}\left(A-D\right)^{3} & \left(A-D\right)^{2}\boldsymbol{t}\alpha+\left(A-D\right)\boldsymbol{t}\alpha\left(A-D\right)+\boldsymbol{t}\alpha\left(A-D\right)^{2}\\
0 & \left(A-D\right)^{3}
\end{bmatrix}\\
\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}\begin{bmatrix}\left(A-D\right)^{3} & \left(A-D\right)^{2}\boldsymbol{t}\alpha+\left(A-D\right)\boldsymbol{t}\alpha\left(A-D\right)+\boldsymbol{t}\alpha\left(A-D\right)^{2}\\
0 & \left(A-D\right)^{3}
\end{bmatrix} & =\begin{bmatrix}\left(A-D\right)^{4} & \left(A-D\right)^{3}\boldsymbol{t}\alpha+\left(A-D\right)^{2}\boldsymbol{t}\alpha\left(A-D\right)+\left(A-D\right)\boldsymbol{t}\alpha\left(A-D\right)^{2}+\boldsymbol{t}\alpha\left(A-D\right)^{3}\\
0 & \left(A-D\right)^{4}
\end{bmatrix}\\
\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i} & =\begin{bmatrix}\left(A-D\right)^{i} & \sum_{j=0}^{i-1}\left(A-D\right)^{i-j}\boldsymbol{t}\alpha\left(A-D\right)^{j}\\
0 & \left(A-D\right)^{i}
\end{bmatrix}\\
\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right)^{i} & \sum_{j=0}^{i-1}\left(A-D\right)^{i-j}\boldsymbol{t}\alpha\left(A-D\right)^{j}\\
0 & \left(A-D\right)^{i}
\end{bmatrix}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix} & =\sum_{j=0}^{i-1}\left(A-D\right)^{i-j}\boldsymbol{t}\alpha\left(A-D\right)^{j}
\end{align*}

\end_inset


\begin_inset Formula 
\begin{align*}
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\sum_{j=0}^{i-1}\left(A-D\right)^{i-j}\boldsymbol{t}\alpha\left(A-D\right)^{j}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\sum_{j=0}^{i-1}L^{i-j}\boldsymbol{t}\alpha L^{j}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\sum_{j=0}^{i-1}L^{i-j}\left(-\left(L+D\right)\boldsymbol{1}\right)\alpha L^{j}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\sum_{j=0}^{i-1}\left(-\left(L^{i-j+1}+L^{i-j}D\right)\boldsymbol{1}\right)\alpha L^{j}\\
\boldsymbol{J} & =\sum_{i=0}^{m_{M}-1}\frac{1}{i!}y^{i}e^{Dy}\sum_{j=0}^{i-1}\left(-\left(L^{i-j+1}\boldsymbol{1}\alpha L^{j}+DL^{i-j}\boldsymbol{1}\alpha L^{j}\right)\right)\\
\end{align*}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\boldsymbol{1}$
\end_inset

 is a column vector of ones and 
\begin_inset Formula $\boldsymbol{t}=-\boldsymbol{A}\boldsymbol{1}$
\end_inset


\end_layout

\begin_layout Standard
(Since 
\begin_inset Formula $\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\begin{bmatrix}\left(A-D\right) & \boldsymbol{t}\alpha\\
0 & \left(A-D\right)
\end{bmatrix}^{i}\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}$
\end_inset

 is scalar, is 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 diagonal?) 
\end_layout

\begin_layout Standard
In general, if 
\begin_inset Formula $\exp M$
\end_inset

 is known (or we have as good of an estimate as we can get) we can calculate
 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 from
\begin_inset Formula 
\begin{align*}
\begin{bmatrix}e^{Ay} & \boldsymbol{J}\\
0 & e^{Ay}
\end{bmatrix} & =\exp\left(\begin{bmatrix}A & \boldsymbol{t}\alpha\\
0 & A
\end{bmatrix}y\right)\\
\boldsymbol{J} & =\begin{bmatrix}\boldsymbol{1}_{n} & \boldsymbol{0}_{n}\end{bmatrix}\exp M\begin{bmatrix}\boldsymbol{0}_{n}\\
\boldsymbol{1}_{n}
\end{bmatrix}
\end{align*}

\end_inset


\end_layout

\end_body
\end_document
